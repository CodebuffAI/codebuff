import { execSync } from 'child_process'
import * as fs from 'fs'
import * as path from 'path'
import { promptClaude } from '../backend/src/claude'
import { countTokens } from '../backend/src/util/token-counter'
import dotenv from 'dotenv'
import { shuffle } from 'lodash'
import { mapAsync } from '../common/src/util/promise'

dotenv.config({ path: path.resolve(__dirname, '../backend/.env') })

const MANICODE_PROJECT_PATH = '/Users/jahooma/manicode'

const PROJECTS_LIST = [
  {
    name: 'pytorch',
    path: `${MANICODE_PROJECT_PATH}/test/__mock-projects__/pytorch`,
  },
  {
    name: 'linux',
    path: `${MANICODE_PROJECT_PATH}/test/__mock-projects__/linux`,
  },
  {
    name: 'jpcsp',
    path: `${MANICODE_PROJECT_PATH}/test/__mock-projects__/jpcsp`,
  },
  {
    name: 'litestar',
    path: `${MANICODE_PROJECT_PATH}/test/__mock-projects__/litestar`,
  },
  {
    name: 'nushell',
    path: `${MANICODE_PROJECT_PATH}/test/__mock-projects__/nushell`,
  },
  {
    name: 'vscode',
    path: `${MANICODE_PROJECT_PATH}/test/__mock-projects__/vscode`,
  },
  {
    name: 'manifold',
    path: '/Users/jahooma/manifold',
  },
]

const NUMBER_OF_COMMITS = 5000
const FILES_TO_PROCESS = 1000
const PARALLEL_PROCESSES = 5

const BLACK_LIST_STRINGS = [
  'This file was automatically generated',
  'This autogenerated file',
]

interface DatasetEntry {
  filePath: string
  oldFile: string
  newFile: string
  patch: string
  claudeSketch: string
}

interface Progress {
  [projectName: string]: DatasetEntry[]
}

const PROGRESS_FILE = `${MANICODE_PROJECT_PATH}/dataset_progress.json`

function saveProgress(projectName: string, dataset: DatasetEntry[]) {
  const progress = loadProgress()
  progress[projectName] = dataset
  fs.writeFileSync(PROGRESS_FILE, JSON.stringify(progress, null, 2))
}

function loadProgress(): Progress {
  if (fs.existsSync(PROGRESS_FILE)) {
    return JSON.parse(fs.readFileSync(PROGRESS_FILE, 'utf-8'))
  }
  return {}
}

async function generateClaudeSketch(
  oldContent: string,
  newContent: string,
  patch: string
): Promise<string> {
  const prompt = `
You are an expert programmer tasked with explaining how to modify an old version of a file into a new version. Your explanation should be clear and concise, suitable for a human to understand and follow.

Here's the old version of the file:

\`\`\`
${oldContent}
\`\`\`

Here's the new version of the file:

\`\`\`
${newContent}
\`\`\`

Here's the patch showing the differences:

\`\`\`
${patch}
\`\`\`

Please provide a sketch of how to turn the old file into the new file. First, explain the changes in a <discussion> block. Then, write out the new file in a <edit_file> block, but use comments like "// ... existing code ..." (or "# ... existing code ..." or similar for different languages) for sections that were unchanged. Don't leave excessive comments.
`

  const response = await promptClaude([{ role: 'user', content: prompt }], {
    userId: 'fine-tuning-dataset-generator',
    ignoreHelicone: true,
  })

  // Extract the content from the <edit_file> block
  const fileContentMatch = response.match(/<edit_file>([\s\S]*?)<\/edit_file>/)
  return fileContentMatch ? fileContentMatch[1].trim() : ''
}

async function createDataset(
  project: { name: string; path: string },
  datasetSoFar: DatasetEntry[]
) {
  console.log(`Creating dataset for project: ${project.name}`)
  const dataset: DatasetEntry[] = datasetSoFar.concat()

  // Create tmp directory if it doesn't exist
  const tmpDir = path.join(process.cwd(), 'tmp')
  if (!fs.existsSync(tmpDir)) {
    fs.mkdirSync(tmpDir)
  }

  // Change to the project directory
  try {
    process.chdir(project.path)
    console.log(`Changed to directory: ${project.path}`)
  } catch (error) {
    console.error(`Failed to change to directory ${project.path}:`, error)
    return
  }

  // Get the last n commit hashes
  const allCommitHashes = execSync(
    `git log -n ${NUMBER_OF_COMMITS} --pretty=format:"%H"`
  )
    .toString()
    .split('\n')

  const allChangedFiles = allCommitHashes.flatMap((commitHash) =>
    execSync(`git diff-tree --no-commit-id --name-only -r ${commitHash}`)
      .toString()
      .split('\n')
      .filter(
        (file) =>
          file.endsWith('.ts') ||
          file.endsWith('.tsx') ||
          file.endsWith('.py') ||
          file.endsWith('.js') ||
          file.endsWith('.jsx') ||
          file.endsWith('.java') ||
          file.endsWith('.go') ||
          file.endsWith('.c') ||
          file.endsWith('.cpp') ||
          file.endsWith('.h') ||
          file.endsWith('.hpp') ||
          file.endsWith('.rs') ||
          file.endsWith('.rb') ||
          file.endsWith('.php') ||
          file.endsWith('.md')
      )
  )

  const alreadyProcessedFiles = new Set(dataset.map((entry) => entry.filePath))
  const shuffledFiles = [...new Set(allChangedFiles)]
    .sort(() => 0.5 - Math.random())
    .filter((file) => !alreadyProcessedFiles.has(file))

  console.log(`Randomly selected ${shuffledFiles.length} files to process.`)

  await mapAsync(
    shuffledFiles,
    async (file) => {
      if (dataset.length >= FILES_TO_PROCESS) return
      try {
        console.log(`Processing file: ${file}`)
        const commitHash = execSync(
          `git log -n 1 --pretty=format:"%H" -- ${file}`
        ).toString()

        // Check the number of lines changed
        const diffStats = execSync(
          `git diff ${commitHash}^ ${commitHash} -- ${file} | grep -E "^[-+]" | wc -l`
        )
          .toString()
          .trim()
        const linesChanged = parseInt(diffStats, 10)

        if (linesChanged < 10) {
          console.log(`Skipping ${file}: Only ${linesChanged} lines changed`)
          return
        }

        // Get the file content before and after the commit
        const oldContent = execSync(`git show ${commitHash}^:${file}`)
          .toString()
          .replace(/\r\n/g, '\n')
        const newContent = execSync(`git show ${commitHash}:${file}`)
          .toString()
          .replace(/\r\n/g, '\n')

        // Check if the file contains any blacklisted strings
        if (
          BLACK_LIST_STRINGS.some(
            (str) => oldContent.includes(str) || newContent.includes(str)
          )
        ) {
          console.log(`Skipping ${file}: Contains blacklisted string`)
          return
        }

        if (
          countTokens(oldContent) > 50_000 ||
          countTokens(newContent) > 50_000
        ) {
          console.log(`Skipping ${file}: File too large`)
          return
        }

        // Generate the git diff patch
        const patch = execSync(
          `git diff ${commitHash}^ ${commitHash} -- ${file}`
        )
          .toString()
          // Remove everything up to the first @@
          .replace(/^[\s\S]*?(?=@@)/m, '')
          .replace(/\r\n/g, '\n')

        // Generate Claude sketch
        console.log(`Generating Claude sketch for ${file}`)
        const claudeSketch = await generateClaudeSketch(
          oldContent,
          newContent,
          patch
        )
        if (!claudeSketch) {
          console.log(`Skipping ${file}: Claude sketch is empty`)
          return
        }

        // Save Claude's sketch to a file in the tmp directory
        const sketchFileName = `${project.name}_${commitHash}_${file.replace(/\//g, '_')}.txt`
        const sketchFilePath = path.join(tmpDir, sketchFileName)
        fs.writeFileSync(sketchFilePath, claudeSketch)
        console.log(`Saved Claude's sketch to ${sketchFilePath}`)

        dataset.push({
          filePath: file,
          oldFile: oldContent,
          newFile: newContent,
          patch: patch,
          claudeSketch: claudeSketch,
        })
        console.log(`Added entry ${dataset.length} for ${file} to dataset.`)
        if (dataset.length % PARALLEL_PROCESSES === 0) {
          console.log(`Saving progress for ${project.name}`)
          saveProgress(project.name, dataset)
        }
      } catch (error: any) {
        console.error(`Error processing file ${file}:`, error.message)
      }
    },
    PARALLEL_PROCESSES
  )

  process.chdir(MANICODE_PROJECT_PATH)

  // Save the dataset to a JSON file
  const outputPath = path.join(
    process.cwd(),
    `fine_tuning_dataset_${project.name}.json`
  )
  fs.writeFileSync(outputPath, JSON.stringify(dataset, null, 2))

  console.log(`Dataset created with ${dataset.length} entries.`)
  console.log(`Dataset saved to: ${outputPath}`)

  // Create fine-tuning-data-[project-name].jsonl
  const jsonlOutputPath = path.join(
    process.cwd(),
    `fine-tuning-data-${project.name}.jsonl`
  )
  const jsonlContent = dataset
    .map((entry) => {
      const oldFileWithLineNumbers = entry.oldFile
        .split('\n')
        .map((line, index) => `${index + 1}|${line}`)
        .join('\n')
      const conversation = {
        messages: [
          {
            role: 'user',
            content: `
Here's an old file:

\`\`\`
${oldFileWithLineNumbers}
\`\`\`

And here's a sketch of the changes:

\`\`\`
${entry.claudeSketch}
\`\`\`

Please produce a patch file based on this change.
`.trim(),
          },
          {
            role: 'assistant',
            content: entry.patch,
          },
        ],
      }
      return JSON.stringify(conversation)
    })
    .join('\n')

  fs.writeFileSync(jsonlOutputPath, jsonlContent)
  console.log(`JSONL file for fine-tuning created at: ${jsonlOutputPath}`)
}

function createTrainingAndValidationDatasets() {
  const currentDate = new Date().toISOString().split('T')[0]
  const allData: string[] = []

  // Read all JSONL files
  PROJECTS_LIST.forEach((project) => {
    const jsonlPath = path.join(
      process.cwd(),
      `fine-tuning-data-${project.name}.jsonl`
    )
    const jsonlContent = fs.readFileSync(jsonlPath, 'utf-8')
    const jsonlData = jsonlContent
      .split('\n')
      .filter((line) => line.trim() !== '')
    allData.push(...jsonlData)
  })

  // Shuffle the data
  const shuffledData = shuffle(allData)

  // Split into training and validation sets
  const splitIndex = Math.floor(shuffledData.length * 0.9)
  const trainingData = shuffledData.slice(0, splitIndex)
  const validationData = shuffledData.slice(splitIndex)

  // Write training data
  const trainingOutputPath = path.join(
    process.cwd(),
    `fine-tuning-training-data-${currentDate}.jsonl`
  )
  fs.writeFileSync(trainingOutputPath, trainingData.join('\n'))
  console.log(`Training data saved to: ${trainingOutputPath}`)

  // Write validation data
  const validationOutputPath = path.join(
    process.cwd(),
    `fine-tuning-validation-data-${currentDate}.jsonl`
  )
  fs.writeFileSync(validationOutputPath, validationData.join('\n'))
  console.log(`Validation data saved to: ${validationOutputPath}`)
}

async function main() {
  if (!process.env.ANTHROPIC_API_KEY) {
    console.error(
      'Error: ANTHROPIC_API_KEY is not set. Please set this environment variable before running the script.'
    )
    return
  }

  const progress = loadProgress()
  for (const project of PROJECTS_LIST) {
    await createDataset(project, progress[project.name] || [])
  }
  createTrainingAndValidationDatasets()
}

main().catch(console.error)
