---
title: 'What models do you use?'
section: 'advanced'
tags: ['introduction', 'faq']
order: 1
---

# What models do you use?

We primarily use Claude 3.5 Sonnet for the coding, and Gemini Flash to find relevant files, and o3-mini for deep thinking.

Codebuff also uses [Relace AI](https://www.relace.ai/) for fast file rewrites.

We have two new modes, which slightly changes the above set-up, mainly to achieve higher performance (in `max`) or lower cost (in `lite`):

- `--max`: uses o3-mini for thinking through hard problems, and does so more frequently. It also uses Claude 3.5 Sonnet for editing and pulls more files, meaning it often gets better context on your codebase.
- `--lite`: uses Claude 3.5 Haiku for editing instead of Sonnet (~1/3 the cost). It also pulls fewer files, meaning that the context cost will be much smaller.

You can use `codebuff --max` or `codebuff --lite` to set the mode at startup time!
